\documentclass[12pt]{article}

\usepackage[colorlinks]{hyperref}

\topmargin 0in
\textheight 8.75in
\textwidth  5.75in

\parskip 5pt


\begin{document}

\title{Ideas for auto-tuning}
\author{Mike Giles}


\maketitle

\begin{abstract}
This document outlines my ideas on developing an auto-tuning
framework.  The initial motivation is the OP2 implementation 
on GPUs, where it is very hard, even for an expert programmer, 
to predict the best way to implement algorithms and the best values 
to use for various parameters (such as number of thread blocks 
and the number of threads per block).  I suspect that auto-tuning 
could deliver performance gains of factor 2 over the initial 
implementation of an expert programmer.

Longer-term, I think that CPU programming is also becoming more 
complex, and it will become harder to achieve good execution 
efficiency.  Auto-tuning may be an important way to reduce this 
performance gap.
\end{abstract}

%\newpage

\section{A bottom-up view}

\subsection{Parametrized codes}

Programs can be parametrized in various ways.

In my current OP2 implementation on GPUs, I am planning to use
the following parameters:
\begin{itemize}
\item
Size of block partition, and hence the number of threads blocks

\item
Number of threads per block

\item
Whether to use thread coloring or atomic increments

\item
Whether to use registers or shared-memory pointers
\end{itemize}
and there will be a set of these for each parallel loop 
in the program.

\newpage

The key observations here are
\begin{itemize}
\item
As an expert programmer I know what the critical parameters
are, but I don't know their optimal value
\item
The parameters are either boolean or integers with a very 
limited set of values (I think I could do well with no more
that 4 possible values)
\end{itemize}

At the practical level, these parameters are embedded within
the C/C++ code as variables which can be set through a 
{\tt \#define} statement or through a {\tt -Dparam=value}
compiler flag.


\subsection{Parametrized compilation and execution}

In addition to parameters within the code, there are also
parameters at the compilation level (e.g.~choice of compiler 
flags, and even choice of compilers).

Within a large-scale enterprise there might also be parameters
at the execution level, such as
\begin{itemize}
\item
whether the application is run on an Intel system or a AMD system

\item
whether it is better to run two 4-thread jobs at the same time, 
or two 8-thread jobs, one after the other
\end{itemize}


\subsection{Optimization}

Finally, we have a heavily parametrized application, and the
goal with auto-tuning is to select the best parameter values.
If there are relatively few parameters and possible parameter 
values then exhaustively checking all combinations may be 
feasible.  In other cases, this would be prohibitively expensive 
and so some form of optimization technique will be required.

The important thing for me is to develop an approach, and
software, which is very generic and able to address 
parameter optimization at the various different levels 
discussed above.  I think this is the key distinguishing 
feature of my objectives compared to what has been done 
previously.

\newpage

\section{A top-down abstract view}

I think a clean software design can often come from looking 
at a problem and constructing a clear abstraction which 
contains the essence of the problem to be addressed.

In this case, I think an appropriate abstraction 
%for the auto-tuning 
has 4 elements:
\begin{itemize}
\item
a figure of merit

This is the quantity to be minimized (or maximized) by 
the optimization.  In my current GPU work, it would be 
the execution time, but if one was choosing which machine 
to execute the application on then the figure of merit 
may be the overall cost of the computation.


\item
a set of parameters and possible parameter values

The user clearly needs to specify the set of parameters
for the optimization, and the set of possible values which
each one can take.  Because high-dimensional optimization 
can be extremely expensive, I think it is important that 
the user should also specify which parameters can be 
optimized independently.  For example, in my GPU work, 
the number of threads used in one GPU kernel is independent
of the number of threads in another kernel and so the 
value of each can be optimized independently.

A possible syntax for specifying this would be:

{\tt \{ param1, param2, \{param3, param4\}, \{param5, param6\} \}}

signifying that the optimal values for {\tt param3, param4} 
depend on each other and {\tt param1, param2} but not on {\tt param5, param6}.

\item
an evaluation mechanism

The auto-tuning framework needs a mechanism to obtain the 
figure of merit for a particular set of parameter values.
The optimization will need to cope with the fact that this
evaluation mechanism is unlikely to be precisely repeatable
(e.g.~the execution time will inevitably vary a bit 
when the code is re-run).  Also, the framework will need to 
be told whether it can run several evaluations at the same time.

\item
an optimization methodology

Finally, we need a method to carry out the optimization.
As stated previously, in simple cases this might be brute-force 
optimization, trying every combination of parameter values,
but in more complex cases it might require something like
genetic algorithm optimization.

\end{itemize}



\begin{figure}
\begin{verbatim}

#
# declare parameters
#

PARAMS = { flags, {thread1, atomics1}, {thread2, atomic2} }

#
# declare possible parameter values
#

flags   = {-O2, -O3}    # compiler flags
thread1 = {32, 64, 96}  # number of threads per block in loop 1
atomic1 = {0, 1}        # boolean for atomic updates in loop 1
thread2 = {32, 64, 96}  # number of threads per block in loop 2
atomic2 = {0, 1}        # boolean for atomic updates in loop 2

#
# declare files to be used
#

PARAMETERS_FILE      = { params.dat }
FIGURE_OF_MERIT_FILE = { f_o_m.dat }

#
# declare evaluation mechanism
#

EVALUATION = { make; ./executable }

#
# declare optimization strategy and how many
# evaluations can be done in parallel
#

STRATEGY = { brute_force parallel:4 }

\end{verbatim}

\caption{An example of a possible configuration file}
\end{figure}

Figure 1 gives a concrete example of a possible configuration file
for defining an auto-tuning optimization.

\end{document}

\section{One year work programme}

\begin{itemize}
\item
develop prototype using MATLAB for optimization

\item
test on GPU application using CMake
{(\tt http://www.cmake.org/)} for 
open-source cross-platform
evaluation under both Windows and Linux

\item
re-do prototype in Python using open-source 
optimization libraries

\item
do additional testing, including getting feedback 
from independent users

\item
add parallel evaluation capability

\item
document everything, including lessons learned and 
strengths and weaknesses
\end{itemize}


\section{Costs}

The ballpark cost for a software developer in OeRC 
(Oxford e-Research Centre) is \pounds 100k per year,
including overheads, which is approximately \$150k 
at the current exchange rate.

If we were to go ahead with this, I would also investigate
the possibility of leveraging additional funds from UK 
government funding agencies.  The difficulty is that the 
usual sources of academic research funding will tend to 
view this as ``just software development'', not containing 
novel computer science which will lead to publications in 
the leading academic journals. My impression is that high 
quality software design and implementation which leads to 
greatly improved productivity and efficiency for both 
academic and commercial computing is not viewed in the UK 
as a legitimate academic endeavor.

(End of rant: as an engineer I accept the world as it is, 
but as a mathematician I dream of a better world.)





\end{document}

